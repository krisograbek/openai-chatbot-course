{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction.\n",
    "\n",
    "In this notebook, you'll learn about tokens - a crucial concept tied directly to Large Language Models (LLMs).\n",
    "\n",
    "\n",
    "\n",
    "Here's what you will learn:\n",
    "- What is a token?\n",
    "- Why do we use tokens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a token?\n",
    "\n",
    "A token is a chunk of text that Large Language Models read or generate.\n",
    "\n",
    "Here's key information about tokens:\n",
    "- A token is the smallest unit of text that AI models process.\n",
    "- Tokens don't have the defined length. Some are only 1 character long, others can be longer words.\n",
    "- Tokens can be: words, sub-words, punctuation marks or special symbols.\n",
    "- As a rule of thumb, a token corresponds to 3/4 of the word. So 100 tokens is roughly 75 words.\n",
    "\n",
    "So let me show you how to count tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why tokens (not characters or words)?\n",
    "\n",
    "#TODO: \n",
    "- Try to explain the drawbacks of character and word approach.\n",
    "- Perplexity: Why do we use tokens in LLMs, not characters or words?\n",
    "- Explain that tokens are the combination of the best from both worlds.\n",
    "- Explain tokens are turned into embeddings inside of LLMs, as they have a lookup table in which they get IDs (tokens). The embedding values are trainable and get updated during the training of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the OpenAI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting 'r' in 'strawberry'\n",
    "\n",
    "Let's use GPT-4o and GPT-4o Mini\n",
    "\n",
    "fg5fctrcqagccccccccae3wcwb vdhjswdhb nsxzz7yf8ug;we.|es\\'3qsa<[]>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word \"strawberry\" contains two 'r' letters.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "strawberry = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"How many 'r' in 'strawberry'?\"}\n",
    "    ],\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "strawberry_resp = strawberry.choices[0].message.content\n",
    "print(strawberry_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe Mountains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mount Everest, the highest peak in the world, stands at an elevation of 8,848.86 meters (29,031.7 feet) above sea level. Located in the Himalayas on the border between Nepal and Tibet, it attracts thousands of climbers each year, including seasoned mountaineers and ambitious adventurers. Despite its allure, climbing Everest presents significant challenges, including extreme weather, high altitudes, and the risk of avalanches.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write 3 sentences about Mount Everest\"}\n",
    "    ],\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "response = completion.choices[0].message.content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's copy the response:\n",
    "\n",
    "```\n",
    "Mount Everest, the highest peak in the world, stands at an elevation of 8,848.86 meters (29,031.7 feet) above sea level. Located in the Himalayas on the border between Nepal and Tibet, it attracts thousands of climbers each year, including seasoned mountaineers and ambitious adventurers. Despite its allure, climbing Everest presents significant challenges, including extreme weather, high altitudes, and the risk of avalanches.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Amazon Rainforest, often referred to as the \"lungs of the Earth,\" spans across several countries in South America, including Brazil, Peru, and Colombia, and plays a crucial role in regulating the global climate. This vast ecosystem is home to approximately 10% of the known species on Earth, showcasing an unparalleled diversity of flora and fauna, many of which are found nowhere else. However, the rainforest faces significant threats from deforestation, illegal logging, and climate change, which jeopardize its invaluable biodiversity and the rights of the indigenous communities that depend on it.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "am_completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write 3 sentences about Amazon Rainforest\"}\n",
    "    ],\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "am_response = am_completion.choices[0].message.content\n",
    "print(am_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's copy:\n",
    "\n",
    "\n",
    "```\n",
    "The Amazon Rainforest, often referred to as the \"lungs of the Earth,\" spans across several countries in South America, including Brazil, Peru, and Colombia, and plays a crucial role in regulating the global climate. This vast ecosystem is home to approximately 10% of the known species on Earth, showcasing an unparalleled diversity of flora and fauna, many of which are found nowhere else. However, the rainforest faces significant threats from deforestation, illegal logging, and climate change, which jeopardize its invaluable biodiversity and the rights of the indigenous communities that depend on it.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We've got a short description about my country, Poland.\n",
    "\n",
    "Let's count words and characters first. In Python it's quite simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response has 92 words and 606 characters.\n"
     ]
    }
   ],
   "source": [
    "words = len(am_response.split())\n",
    "characters = len(am_response)\n",
    "\n",
    "print(f\"The response has {words} words and {characters} characters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting tokens.\n",
    "\n",
    "To count tokens, we'll use the `tiktoken` library.\n",
    "\n",
    "Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response has 113 tokens.\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "\n",
    "tokens = enc.encode(am_response)\n",
    "print(f\"The response has {len(tokens)} tokens.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break the code down:\n",
    "- We imported the tiktoken library.\n",
    "- We defined the encoder using `encoding_for_model(\"gpt-4o-mini\")` to ensure we use the right encoder.\n",
    "- We \"tokenized\" the response using `encode(pl_response)`.\n",
    "- We counted the tokens using Python's `len` function.\n",
    "\n",
    "Great!\n",
    "\n",
    "Let's take our sample text and run it through the [online tokenizer](https://tiktokenizer.vercel.app/).\n",
    "\n",
    "Here are the results:\n",
    "\n",
    "<img src=\"./images/AmazonDescTokens.png\" alt=\"Amazon Description tokens\" width=\"500px\" />\n",
    "\n",
    "I love that visual representation. The app highlights every single token. It helps us see how they actually look like.\n",
    "\n",
    "Below, we can see the numerical representation of each token from the decription.\n",
    "\n",
    "Let's try to see, if the numbers match with the tokens from the `tiktoken` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[976, 9529, 33159, 76428, 11, 4783, 22653, 316, 472, 290, 392, 82576, 328, 290, 16464, 3532, 78545, 5251, 4919, 8981, 306, 6800, 8108, 11, 3463, 24868, 11, 61802, 11, 326, 41071, 11, 326, 17473, 261, 19008, 5430, 306, 101955, 290, 5466, 16721, 13, 1328, 11332, 38423, 382, 2237, 316, 16679, 220, 702, 4, 328, 290, 5542, 15361, 402, 16464, 11, 86573, 448, 88238, 28955, 328, 90258, 326, 98806, 11, 1991, 328, 1118, 553, 2491, 51180, 1203, 13, 5551, 11, 290, 164436, 22060, 6933, 35649, 591, 1056, 192522, 11, 23802, 17553, 11, 326, 16721, 3343, 11, 1118, 108527, 750, 1617, 69505, 106248, 326, 290, 6393, 328, 290, 68509, 15061, 484, 9630, 402, 480, 13]\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why counting tokens?\n",
    "\n",
    "When creating AI applications, it's crucial to manage (and count) tokens for several reasons:\n",
    "1. **Cost management** - Tokens directly influence the cost of API usage.\n",
    "2. **Billing accuracy** - Token counting enables accurate usage-based billing for customers.\n",
    "3. **Performance optimization** - The number of tokens affects model performance. Monitoring token usage helps optimize prompts.\n",
    "4. **Customer transparency** - Providing real-time token usage data to customers through dashboards helps them control their spending and avoid unexpected costs.\n",
    "5. **Product optimization** - Analyzing token usage patterns can provide insights into how customers are using the AI product, informing future improvements and feature development.\n",
    "6. **Compliance and security**-  Monitoring token usage can help detect unusual patterns that might indicate security issues.\n",
    "7. **Profitability analysis** - By attributing token usage to specific customers or features, companies endure profitability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polish Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazonia, często nazywana \"płucami Ziemi\", rozciąga się na kilku krajach Ameryki Południowej, w tym w Brazylii, Peru i Kolumbii, i odgrywa kluczową rolę w regulacji globalnego klimatu. Ten ogromny ekosystem jest domem dla około 10% znanych gatunków na Ziemi, prezentując niezrównaną różnorodność flory i fauny, z których wiele nie występuje nigdzie indziej. Jednak las deszczowy stoi w obliczu poważnych zagrożeń związanych z wylesianiem, nielegalnym wyrębem drzew i zmianami klimatycznymi, które zagrażają jego bezcennej bioróżnorodności oraz prawom społeczności rdzennych, które od niego zależą.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Translate to Polish the following: \" + am_response\n",
    "\n",
    "polish = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "translation = polish.choices[0].message.content\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### German Translation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
