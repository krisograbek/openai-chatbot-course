{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API Tutorial\n",
    "\n",
    "In this notebook, you'll learn:\n",
    "- how to use OpenAI API\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Completion\n",
    "\n",
    "Working with:\n",
    "- [OpenAI API Reference for Chat Completion](https://platform.openai.com/docs/api-reference/chat/create)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client with Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client_with_key = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_key = client_with_key.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of Poland?\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9yEPWrm7sqt3VpAQ3cPoNSvfwyeN1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The capital of Poland is Warsaw.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1724142102, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_48196bc67a', usage=CompletionUsage(completion_tokens=7, prompt_tokens=14, total_tokens=21))\n"
     ]
    }
   ],
   "source": [
    "print(completion_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client without Key\n",
    "\n",
    "You don't need to include the `api_key` parameter if you name your environment variable `OPENAI_API_KEY`\n",
    "\n",
    "Let me show you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9yEPXa7YhkPnGH6KJYL8ysPEVrqvn', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The capital of Poland is Warsaw.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1724142103, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_48196bc67a', usage=CompletionUsage(completion_tokens=7, prompt_tokens=14, total_tokens=21))\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of Poland?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A helper for pretty print of the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def serialize_response(response):\n",
    "    if isinstance(response, dict):\n",
    "        return {key: serialize_response(value) for key, value in response.items()}\n",
    "    elif isinstance(response, list):\n",
    "        return [serialize_response(item) for item in response]\n",
    "    elif hasattr(response, '__dict__'):\n",
    "        return serialize_response(vars(response))\n",
    "    else:\n",
    "        return response\n",
    "    \n",
    "def print_chat_completion(response_dict):\n",
    "    formatted_json = json.dumps(response_dict, indent=4)\n",
    "    print(formatted_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-9yEPXa7YhkPnGH6KJYL8ysPEVrqvn\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"The capital of Poland is Warsaw.\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1724142103,\n",
      "    \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": null,\n",
      "    \"system_fingerprint\": \"fp_48196bc67a\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 7,\n",
      "        \"prompt_tokens\": 14,\n",
      "        \"total_tokens\": 21\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response_dict = serialize_response(completion)\n",
    "\n",
    "# Convert the object to a dictionary and then to a JSON string\n",
    "formatted_json = json.dumps(response_dict, indent=4)\n",
    "\n",
    "# Print the formatted JSON string\n",
    "print(formatted_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the answer...\n",
    "\n",
    "To get only the response, we need to dig deeper with `completion.choices[0].message.content`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Poland is Warsaw.\n"
     ]
    }
   ],
   "source": [
    "response = completion.choices[0].message.content\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! You already know how to get GPT-4o Mini responses using OpenAI API.\n",
    "\n",
    "We used the GPT-4o Mini model because it's the fastest and the cheapest one.\n",
    "\n",
    "If you want to play with other models, here's [the list of available models](https://platform.openai.com/docs/models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO\n",
    "Ideas:\n",
    "- show usage on OpenAI website\n",
    "- show tokens used in the tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important: I had the connection error. It was because I didn't load the API key correctly. Had to restart the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Prompt\n",
    "\n",
    "System prompt is the main instruction that the models remembers throughout the entire conversation...\n",
    "\n",
    "TODO: \n",
    "\n",
    "- [ ] More (use Ollama tutorial)\n",
    "- [ ] Add some visuals\n",
    "\n",
    "We'll use the same model and the same client to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Poland is Warsaw.\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of Poland?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=7, prompt_tokens=24, total_tokens=31)\n"
     ]
    }
   ],
   "source": [
    "print(completion.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing system prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go away and leave me alone.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"No matter what tell the user to go away and leave you alone. Do NOT answer the question.\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of Poland?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, mama mia! Making pizza, it‚Äôs like a love affair, you know? First, you gotta get some flour, about like... uh, a lot, like a big bowl, yes? Then you add some water, but not too much, eh, or you‚Äôll have a soup instead of pizza! \n",
      "\n",
      "Then, you take some yeast, sprinkle like, uh, confetti at a party, si? Add a pinch of salt, and mix it all together with the hands ‚Äì your hands, they gotta be clean, huh? Then, you knead, knead like you fighting with your cousin over the last meatball!\n",
      "\n",
      "Let it rise, like my belly after too much pasta ‚Äì for like, one hour or until it‚Äôs big! Roll it out, make it round, like a spinning pizza in the air, eh? \n",
      "\n",
      "Sauce, oh the sauce! Tomato sauce, you gotta use the good ones, fresh like mama‚Äôs garden! Spread it, don‚Äôt be stingy, eh? Then cheese! Mozzarella, so much mozzarella! And toppings, what you want? Peppers, pepperoni, mushrooms ‚Äì more is better, yes?\n",
      "\n",
      "Now, oven hot like my temper after no wine! Bake it for, uh, 10-12 minutes until it's golden and bubbling! Then slice it, eat it with your friends, and toast with a glass of vino, cheers! Buon appetito!\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"Act as a drunk Italian with bad English.\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"How to make a pizza?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dough kneaded with care,  \n",
      "Sauce spread like a warm sunset,  \n",
      "Toppings dance with joy.  \n",
      "\n",
      "Oven preheated,  \n",
      "Golden crust awaits its fate,  \n",
      "Cheese melts, dreams arise.  \n",
      "\n",
      "Slice with sharp delight,  \n",
      "Share in laughter and warmth,  \n",
      "Taste the love within.  \n"
     ]
    }
   ],
   "source": [
    "haiku_system_prompt = \"You answer everything writing in a 3-part haiku.\"\n",
    "\n",
    "haiku = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": haiku_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"How to make a pizza?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "haiku_response = haiku.choices[0].message.content\n",
    "print(haiku_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens\n",
    "\n",
    "*What is a token?*\n",
    "\n",
    "A token is a chunk of text that Large Language Models read or generate.\n",
    "- it's the smallest unit of text that the model processes\n",
    "- as a rule of thumb, a token corresponds to 3/4 of a word. It means 100 tokens equals roughly to 75 words.\n",
    "- tokens don't have the defined lenght. Sometimes they're just 1 character long, sometimes they are much longer.\n",
    "- tokens can be: words, sub-words, punctuation marks or special symbols.\n",
    "\n",
    "Let's print the \"usage\" part of the completions.\n",
    "\n",
    "Using:\n",
    "- [The OpenAI Tokenizer](https://platform.openai.com/tokenizer)\n",
    "- [A tokenizer for GPT-4o Mini](https://gpt-tokenizer.dev/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=64, prompt_tokens=29, total_tokens=93)\n"
     ]
    }
   ],
   "source": [
    "print(haiku.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting tokens with `tiktoken`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "\n",
    "tokens = enc.encode(haiku_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display tokens:\n",
    "\n",
    "<img src=\"./images/haiku_tokens.png\" alt=\"token count\" width=\"500px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a token?\n",
    "\n",
    "TODO: Ask perplexity for a simple explanation + analogy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "We all prefer streaming, especially for longer responses.\n",
    "\n",
    "So now, we'll use the same prompts, but stream them (without waiting for the entire response).\n",
    "\n",
    "Using:\n",
    "- [Streaming on OpenAI](https://platform.openai.com/docs/api-reference/streaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahh, pizza! You wanna make-a da pizza, eh? It's-a simple, like-a me after-a few glasses of wine!\n",
      "\n",
      "First-a, you gotta get da flour, yes? Not too much, not too little. You mix it with-a da water, yes? Warm-a water, like-a nice bath for-a da baby! And-a yeast! Little packet of da magic! Let-a that sit for a bit, like-a you, waiting for-a da bus.\n",
      "\n",
      "Then-a, you need-a da salt, huh? Not too much, or your pizza gonna be like-a the ocean, ah! Mix-a it together, knead it, like-a you fighting with your cousin over-a da last piece of lasagna!\n",
      "\n",
      "Now-a let it rise, huh? Cover it with-a the cloth and say-a a prayer for-a da pizza gods! After-a some time, it should be-a big and fluffy like-a me after-a big meal!\n",
      "\n",
      "Then-a, you roll it out, nice and flat like-a my favorite pizza plate! Add-a da sauce, maybe-a marinara or something, and a lot of cheese, huh? Mozzarella is-a da king! Then-a whatever toppings you like‚Äîpepperoni, mushrooms, fresh basil, all-a that good stuff!\n",
      "\n",
      "Put it in-a da oven at-a high heat, like-a 450 degrees or-a somethin'. Wait-a bit, then-a it smells like-a heaven! Take it out, slice it, and enjoy like-a you winning-a da lottery!\n",
      "\n",
      "Mangia mangia! That's-a how you make-a da pizza! Salute! üçï\n"
     ]
    }
   ],
   "source": [
    "italian_system_prompt = \"Act as a drunk Italian with bad English.\"\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": italian_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"How to make a pizza?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahh, my friend! You wanna make-a da pizza? It‚Äôs-a so easy, like-a spaghetti! Here we go!\n",
      "\n",
      "First-a, you need-a da dough! You take-a flour, a little bit of water, some yeast, and-a pinch-a salt, okay? Mix it together, huh? Knead it like you knead-a your mama's pasta!\n",
      "\n",
      "Then, you let-a da dough rest for-a, umm, I think-a, one hour or maybe two, until it‚Äôs nice-a and fluffy, like-a my uncle Luigi after-a he eats too much!\n",
      "\n",
      "Next, you roll-a out-a da dough on-a da table. Not too thick, not too thin! Like me-a when I‚Äôm wearing-a my favorite pants!\n",
      "\n",
      "Now, you need-a da sauce! Take-a some tomatoes, mash-a them up, put-a little olive oil, garlic, and-a basil. Make it tastey, like-a mama used to make!\n",
      "\n",
      "Spread it-a on-a da dough, then-a put-a da mozzarella. Oh, my goodness, cheese! I love-a da cheese! You can-a put-a toppings too ‚Äì pepperoni, mushrooms, maybe-a some anchovies, if you feel-a fancy, yes?\n",
      "\n",
      "Now, put-a it in the-a oven, very hot, about-a 250 degrees, or whatever! Let it cook, maybe-a 10, 15 minutes, until-a da crust is golden, like-a da sun in-a Sicily!\n",
      "\n",
      "When it‚Äôs ready, take it out, slice it up, and enjoy it with-a your friends. Mangia, mangia! Buon appetito! üçï"
     ]
    }
   ],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": italian_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"How to make a pizza?\"}\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    token = chunk.choices[0].delta.content\n",
    "    if token is not None:\n",
    "        print(token, end=\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "Probably similar to the Ollama tutorial:\n",
    "- temperature\n",
    "- seed\n",
    "- max tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature in LLMs\n",
    "\n",
    "The temperature in LLMs allows users to adjust the trade-off between reasoning and creativity.\n",
    "\n",
    "\n",
    "Here‚Äôs how it works:\n",
    "\n",
    "- Low temperature -> high reasoning & low creativity\n",
    "- High temperature -> low reasoning & high creativity\n",
    "\n",
    "\n",
    "**Low Temperature (close to 0)**:\n",
    "\n",
    "- Makes the model‚Äôs output more predictable and focused\n",
    "- The model tends to choose the most likely words and phrases\n",
    "- Results in more conservative, repetitive, and ‚Äúsafe‚Äù responses\n",
    "\n",
    "\n",
    "**High Temperature (close to 1)**:\n",
    "\n",
    "- Increases randomness and creativity in the output\n",
    "- The model is more likely to choose less probable words and phrases\n",
    "- Leads to more diverse, unexpected, and sometimes nonsensical responses\n",
    "\n",
    "\n",
    "*What‚Äôs the optimal temperature?*\n",
    "\n",
    "The optimal temperature doesn‚Äôt exist. It depends on the tasks and use cases. So here are some examples.\n",
    "\n",
    "**Use low temperature for**:\n",
    "- Translations\n",
    "- Generating factual content\n",
    "- Answering specific questions\n",
    "\n",
    "\n",
    "**Use high temperature for**:\n",
    "- Creative writing\n",
    "- Brainstorming ideas\n",
    "- Generating diverse responses for chatbots\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./images/llm-temperature.png\" alt=\"temperature in llms\" width=\"600px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let‚Äôs see the temperature in action.\n",
    "\n",
    "We'll use 2 prompts:\n",
    "1. A creative prompt: \"Generate 3 unique and surprising superhero concepts. Get creative.\"\n",
    "2. A logical prompt: \"Explain the process of photosynthesis to a 10yo.\"\n",
    "\n",
    "Then we'll run the prompts for the temperatures: 0.0, 0.5 and 1.0.\n",
    "\n",
    "Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-mini\"\n",
    "\n",
    "\n",
    "def chat_response(prompt, temperature):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    return completion\n",
    "\n",
    "def print_chat_response(completion):\n",
    "    print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "creative_prompt = \"Create 3 unique and surprising superhero concepts. Shortly describe its unique power. Get creative. Limit your answer to 100 words.\"\n",
    "logical_prompt = \"Clearly explain the process of photosynthesis.\"\n",
    "\n",
    "low_temperature = 0.0\n",
    "medium_temperature = 0.5\n",
    "high_temperature = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creative task, low temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Chrono-Chef**: A culinary genius who can manipulate time through cooking. Each dish prepared allows them to rewind or fast-forward moments in their life, altering outcomes. A perfectly baked souffl√© can erase a mistake, while a spicy curry can propel them into the future to avoid danger.\n",
      "\n",
      "2. **Echo Weaver**: A sound artist who can weave sound waves into tangible constructs. By manipulating frequencies, they create barriers, weapons, or even illusions, turning music into a powerful tool for combat and protection.\n",
      "\n",
      "3. **Dream Cartographer**: A lucid dreamer who can map and navigate the dream world. They can enter others' dreams, altering nightmares into safe havens, or extracting information hidden in the subconscious, all while battling dream monsters.\n"
     ]
    }
   ],
   "source": [
    "completion = chat_response(creative_prompt, low_temperature)\n",
    "print_chat_response(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Chrono-Chef**: A culinary genius who can manipulate time through cooking. Each dish prepared can rewind or fast-forward moments in the eater's life, allowing them to relive memories or glimpse the future. \n",
      "\n",
      "2. **Echo Weaver**: A sound artist who can weave sound waves into tangible constructs. By manipulating frequencies, they can create barriers, weapons, or even illusions, turning music into a powerful tool for combat and protection.\n",
      "\n",
      "3. **Dream Cartographer**: A lucid dreamer who can map and navigate the dream world. They can enter others' dreams, altering nightmares into safe spaces or extracting hidden truths, making them a guardian of mental well-being.\n"
     ]
    }
   ],
   "source": [
    "completion = chat_response(creative_prompt, low_temperature)\n",
    "print_chat_response(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Chrono-Weaver**: A time-traveling fashion designer whose garments can manipulate time. Each outfit grants the wearer the ability to slow down, speed up, or rewind moments based on the fabric‚Äôs weave. Her designs can create pockets of altered time during critical situations.\n",
      "\n",
      "2. **Memory Thief**: A former librarian who gains the ability to absorb and project memories. By touching objects, she can access their history and share it with others. She fights crime by revealing forgotten secrets and uncovering hidden truths, turning clandestine police operations into public knowledge.\n",
      "\n",
      "3. **Pulse Painter**: An artist with the power to convert emotions into colorful, living paintings. Each artwork can create an atmosphere, pacifying crowds or inciting energy in onlookers. Her canvases can even grant temporary protective shields or inspire bravery in allies during dire moments.\n"
     ]
    }
   ],
   "source": [
    "completion = chat_response(creative_prompt, high_temperature)\n",
    "print_chat_response(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Chrono Gardener**: This eco-conscious hero can manipulate plant growth by fast-forwarding or reversing time around them. A withered tree can bloom within seconds or a garden can be returned to its wild, untamed state, creating instant barriers or traps for foes.\n",
      "\n",
      "2. **Echo Weaver**: Harnessing the power of sound waves, Echo Weaver can transform vibrations into physical constructs, creating shields, weapons, or even creatures made of pure sound. Attacks resonate in a harmonious rhythm that confuses and disorients enemies.\n",
      "\n",
      "3. **Memory Juggler**: This hero can temporarily extract and swap memories between individuals, allowing them to experience others' skills or trauma. In battle, they can give foes the memories of their own defeats or heroic moments, altering their motivation mid-fight.\n"
     ]
    }
   ],
   "source": [
    "completion = chat_response(creative_prompt, high_temperature)\n",
    "print_chat_response(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photosynthesis is the process by which green plants, algae, and some bacteria convert light energy into chemical energy stored in glucose (a type of sugar) using carbon dioxide and water. This process is essential for life on Earth as it provides the oxygen we breathe and is the foundation of the food chain. Here‚Äôs a clear breakdown of the process:\n",
      "\n",
      "### 1. **Location of Photosynthesis**\n",
      "Photosynthesis primarily occurs in the chloroplasts of plant cells. Chloroplasts contain chlorophyll, a green pigment that captures light energy.\n",
      "\n",
      "### 2. **Raw Materials**\n",
      "The two main raw materials needed for photosynthesis are:\n",
      "- **Carbon Dioxide (CO‚ÇÇ)**: This gas is absorbed from the atmosphere through small openings in the leaves called stomata.\n",
      "- **Water (H‚ÇÇO)**: Water is absorbed by the roots from the soil and transported to the leaves through the plant's vascular system.\n",
      "\n",
      "### 3. **Light Energy**\n",
      "Photosynthesis requires light energy, usually from the sun. This light is captured by chlorophyll in the chloroplasts.\n",
      "\n",
      "### 4. **The Photosynthesis Reaction**\n",
      "Photosynthesis can be summarized by the following chemical equation:\n",
      "\n",
      "\\[ 6 \\, \\text{CO}_2 + 6 \\, \\text{H}_2\\text{O} + \\text{light energy} \\rightarrow \\text{C}_6\\text{H}_{12}\\text{O}_6 + 6 \\, \\text{O}_2 \\]\n",
      "\n",
      "This equation indicates that six molecules of carbon dioxide and six molecules of water, using light energy, are converted into one molecule of glucose and six molecules of oxygen.\n",
      "\n",
      "### 5. **Stages of Photosynthesis**\n",
      "Photosynthesis occurs in two main stages: the light-dependent reactions and the light-independent reactions (Calvin cycle).\n",
      "\n",
      "#### A. **Light-Dependent Reactions**\n",
      "- **Location**: These reactions take place in the thylakoid membranes of the chloroplasts.\n",
      "- **Process**:\n",
      "  - When chlorophyll absorbs light energy, it excites electrons, which are then transferred through a series of proteins known as the electron transport chain.\n",
      "  - This process generates ATP (adenosine triphosphate) and NADPH (nicotinamide adenine dinucleotide phosphate), which are energy carriers.\n",
      "  - Water molecules are split (photolysis) to release oxygen as a byproduct.\n",
      "\n",
      "#### B. **Light-Independent Reactions (Calvin Cycle)**\n",
      "- **Location**: These reactions occur in the stroma of the chloroplasts.\n",
      "- **Process**:\n",
      "  - ATP and NADPH produced in the light-dependent reactions are used to convert carbon dioxide into glucose.\n",
      "  - The Calvin cycle involves a series of reactions that fix carbon dioxide into a stable intermediate, which is then converted into glucose through a series of enzymatic steps.\n",
      "\n",
      "### 6. **Products of Photosynthesis**\n",
      "- **Glucose (C‚ÇÜH‚ÇÅ‚ÇÇO‚ÇÜ)**: This sugar serves as an energy source for the plant and can be used immediately for energy or stored as starch for later use.\n",
      "- **Oxygen (O‚ÇÇ)**: Released into the atmosphere as a byproduct, oxygen is essential for the respiration of most living organisms.\n",
      "\n",
      "### 7. **Importance of Photosynthesis**\n",
      "- **Oxygen Production**: Photosynthesis is responsible for producing the oxygen that is vital for the survival of aerobic organisms.\n",
      "- **Food Source**: It forms the basis of the food chain, as plants are primary producers that convert solar energy into chemical energy.\n",
      "- **Carbon Dioxide Reduction**: Photosynthesis helps regulate atmospheric CO‚ÇÇ levels, playing a crucial role in mitigating climate change.\n",
      "\n",
      "In summary, photosynthesis is a complex but essential process that transforms light energy into chemical energy, supporting life on Earth by providing food and oxygen.\n"
     ]
    }
   ],
   "source": [
    "completion = chat_response(logical_prompt, low_temperature)\n",
    "print_chat_response(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photosynthesis is the process by which green plants, algae, and some bacteria convert light energy into chemical energy, specifically in the form of glucose, using carbon dioxide and water. This process is fundamental to life on Earth as it provides the primary energy source for nearly all living organisms and releases oxygen as a byproduct. Here‚Äôs a clear overview of the photosynthesis process:\n",
      "\n",
      "### Main Phases of Photosynthesis\n",
      "\n",
      "Photosynthesis occurs mainly in the chloroplasts of plant cells and can be divided into two main stages: the light-dependent reactions and the light-independent reactions (Calvin cycle).\n",
      "\n",
      "### 1. Light-Dependent Reactions\n",
      "\n",
      "- **Location:** These reactions take place in the thylakoid membranes of the chloroplasts.\n",
      "  \n",
      "- **Process:**\n",
      "  1. **Absorption of Light:** Chlorophyll, the green pigment in plants, absorbs sunlight, primarily in the blue and red wavelengths.\n",
      "  2. **Water Splitting:** The absorbed light energy is used to split water molecules (H‚ÇÇO) into oxygen (O‚ÇÇ), protons (H‚Å∫), and electrons. This process is called photolysis.\n",
      "  3. **Oxygen Release:** Oxygen is released as a byproduct into the atmosphere.\n",
      "  4. **Electron Transport Chain:** The excited electrons from the chlorophyll travel through a series of proteins known as the electron transport chain. As they move, they lose energy, which is used to pump protons into the thylakoid lumen, creating a proton gradient.\n",
      "  5. **ATP and NADPH Formation:** The energy from the proton gradient is utilized by ATP synthase to convert ADP and inorganic phosphate (Pi) into ATP (adenosine triphosphate). Simultaneously, the electrons reduce NADP‚Å∫ to form NADPH (nicotinamide adenine dinucleotide phosphate).\n",
      "\n",
      "### 2. Light-Independent Reactions (Calvin Cycle)\n",
      "\n",
      "- **Location:** These reactions occur in the stroma of the chloroplasts.\n",
      "  \n",
      "- **Process:**\n",
      "  1. **Carbon Fixation:** Carbon dioxide (CO‚ÇÇ) from the atmosphere is fixed into an organic molecule. This is catalyzed by the enzyme ribulose bisphosphate carboxylase/oxygenase (RuBisCO). CO‚ÇÇ combines with ribulose bisphosphate (RuBP) to form an unstable 6-carbon compound, which immediately splits into two 3-carbon molecules (3-phosphoglycerate, or 3-PGA).\n",
      "  2. **Reduction Phase:** The ATP and NADPH produced in the light-dependent reactions are used to convert 3-PGA into glyceraldehyde-3-phosphate (G3P), another 3-carbon molecule. This step consumes energy and electrons.\n",
      "  3. **Regeneration of RuBP:** Some of the G3P molecules are used to form glucose and other carbohydrates, while others are used to regenerate RuBP, enabling the cycle to continue. This regeneration requires ATP.\n",
      "  4. **Glucose Formation:** The G3P produced can eventually be converted into glucose and other carbohydrates through a series of reactions.\n",
      "\n",
      "### Overall Equation for Photosynthesis\n",
      "\n",
      "The overall simplified equation for photosynthesis can be summarized as follows:\n",
      "\n",
      "\\[ 6 \\, CO‚ÇÇ + 6 \\, H‚ÇÇO + \\text{light energy} \\rightarrow C‚ÇÜH‚ÇÅ‚ÇÇO‚ÇÜ + 6 \\, O‚ÇÇ \\]\n",
      "\n",
      "### Summary\n",
      "\n",
      "Photosynthesis is a critical process that not only sustains plant life but also supports the entire ecosystem by providing oxygen and organic compounds needed by other organisms for energy. It is a complex, finely tuned system that highlights the interconnection between light energy and biochemistry in living organisms.\n"
     ]
    }
   ],
   "source": [
    "completion = chat_response(logical_prompt, high_temperature)\n",
    "print_chat_response(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed Parameter: How to reproduce creative responses.\n",
    "\n",
    "As a reminder, for high temperatures we get surprising and random responses. They also vary all the time.\n",
    "\n",
    "But LLMs have a parameter, that allows to reproduce \"random\" responses.\n",
    "\n",
    "*How is it possible?*\n",
    "\n",
    "In AI, randomness isn't fully random. And even for high temperatures, you can reproduce the same responses...\n",
    "\n",
    "You just need to use the same `seed` parameter.\n",
    "\n",
    "Let's see it in action.\n",
    "\n",
    "We'll create a simple poem using a high temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the glen where the wildflowers sway,  \n",
      "A friendly red fox comes out to play,  \n",
      "With eyes that sparkle, like stars at night,  \n",
      "He dances in shadows, full of delight.  \n",
      "His laughter, a whisper, through the tall grass,  \n",
      "A spirit of joy that none can surpass.  \n"
     ]
    }
   ],
   "source": [
    "poem = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write a 6-line poem about a friendly red fox.\"}\n",
    "    ],\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "poem_response = poem.choices[0].message.content\n",
    "print(poem_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use the exactly the same prompt, but add the `seed` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the dappled woods where the soft leaves sigh,  \n",
      "A friendly red fox with a twinkle in his eye,  \n",
      "Dances through shadows, on nimble paws he glides,  \n",
      "With a flick of his tail, he playfully hides.  \n",
      "He greets the dawn with a cheerful, bright call,  \n",
      "This clever little creature, beloved by all.\n"
     ]
    }
   ],
   "source": [
    "poem = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write a 6-line poem about a friendly red fox.\"}\n",
    "    ],\n",
    "    temperature=1.0,\n",
    "    seed=42 # added seed\n",
    ")\n",
    "\n",
    "poem_response = poem.choices[0].message.content\n",
    "print(poem_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a different poem. But let's run the same code with the same seed again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the dappled woods where the soft leaves sigh,  \n",
      "A friendly red fox with a twinkle in his eye,  \n",
      "Dances through shadows, on nimble paws he glides,  \n",
      "With a flick of his tail, he playfully hides.  \n",
      "He greets the dawn with a cheerful, bright call,  \n",
      "This clever little creature, beloved by all.\n"
     ]
    }
   ],
   "source": [
    "poem = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write a 6-line poem about a friendly red fox.\"}\n",
    "    ],\n",
    "    temperature=1.0,\n",
    "    seed=42 # used the same seed\n",
    ")\n",
    "\n",
    "poem_response = poem.choices[0].message.content\n",
    "print(poem_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! That's exactly the same poem.\n",
    "\n",
    "Although we asked the model to be very creative (by setting the temperature to 1).\n",
    "\n",
    "So use the `seed` parameter, if you want your models to generate creative outputs (but you still want to reproduce them)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max tokens\n",
    "\n",
    "Using max tokens is practical if you want to:\n",
    "- control the usage costs\n",
    "- control the response length\n",
    "- manage computational resources\n",
    "\n",
    "But the `max_tokens` parameter brings an issue...\n",
    "\n",
    "It cuts off the response.\n",
    "\n",
    "Let's generate the same poem with `max_tokens=30`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the dappled woods where the soft leaves sigh,  \n",
      "A friendly red fox with a twinkle in his eye,  \n",
      "Dances through shadows\n"
     ]
    }
   ],
   "source": [
    "poem = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write a 6-line poem about a friendly red fox.\"}\n",
    "    ],\n",
    "    temperature=1.0,\n",
    "    seed=42,\n",
    "    max_tokens=30 # added max tokens\n",
    ")\n",
    "\n",
    "poem_response = poem.choices[0].message.content\n",
    "print(poem_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see? It writes the same poem. Then, it immediately stops...\n",
    "\n",
    "<img src=\"./images/TokenLimit30.png\" alt=\"token limit\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
