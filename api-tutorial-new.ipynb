{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction.\n",
    "\n",
    "In this notebook, we'll explore how to use OpenAI Large Language Models (LLMs) using OpenAI API.\n",
    "\n",
    "**OpenAI API** gives developers access to the state-of-the-art LLMs via Python code.\n",
    "\n",
    "Using AI models, such as GPT-4o or GPT-4o Mini is quite straightforward. It also has advantages over using tools such as ChatGPT:\n",
    "- Access to models parameters.\n",
    "- Access to the system prompt.\n",
    "- Ability to connect models.\n",
    "\n",
    "So it gives higher customization and control options.\n",
    "\n",
    "In this notebook, we'll go through the following topics:\n",
    "- Using GPT-4o and GPT-4o Mini via OpenAI API.\n",
    "- The importance of the system prompt.\n",
    "- Streaming responses.\n",
    "- The detailed explanation of tokens.\n",
    "- The practical applications of temperature.\n",
    "And more!\n",
    "\n",
    "To successfully run the notebook, you need to install several packages:\n",
    "- **OpenAI API**: `openai` - the library to use OpenAI models via API calls.\n",
    "- **Python Dotenv**: `python-dotenv` - to load secret variables from the .env file.\n",
    "- **Tiktoken**: `tiktoken `- for counting tokens.\n",
    "\n",
    "To install them, run the following command in your terminal:\n",
    "\n",
    "```bash\n",
    "$ pip install openai python-dotenv tiktoken\n",
    "```\n",
    "\n",
    "OK, let's move on the the coding part!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading API keys\n",
    "\n",
    "To make OpenAI API calls, we need a secret key.\n",
    "\n",
    "I usually save the key in a `.env` file. Here's how it looks:\n",
    "\n",
    "`OPENAI_API_KEY=sk-proj-your-actual-key-here`\n",
    "\n",
    "Then, I load it using the `python-dotenv` library like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the OpenAI client.\n",
    "\n",
    "To work with OpenAI API, we need to use the `OpenAI()` class. The common practice is to call it this way:\n",
    "\n",
    "`client = OpenAI()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with the simplest completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Poland is Warsaw.\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the capiatal of Poland?\"}]\n",
    ")\n",
    "\n",
    "response = completion.choices[0].message.content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digging into `completion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-A0S2AMEAXSpgqsUT2GjB16SMlvsGG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The capital of Poland is Warsaw.', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1724671126, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_f3db212e1c', usage=CompletionUsage(completion_tokens=7, prompt_tokens=16, total_tokens=23))\n"
     ]
    }
   ],
   "source": [
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, it's an objecdt of type `ChatCompletion` by OpenAI API.\n",
    "\n",
    "But, let's print it in a nicer way.\n",
    "\n",
    "First, we need a helper function for that.\n",
    "\n",
    "*Note: The function is here only to display the `ChatCompletion` object in a readible way. It has nothing to do with AI itself.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def serialize_completion(completion):\n",
    "    if isinstance(completion, dict):\n",
    "        return {key: serialize_completion(value) for key, value in completion.items()}\n",
    "    elif isinstance(completion, list):\n",
    "        return [serialize_completion(item) for item in completion]\n",
    "    elif hasattr(completion, '__dict__'):\n",
    "        return serialize_completion(vars(completion))\n",
    "    else:\n",
    "        return completion\n",
    "    \n",
    "def print_chat_completion(response_dict):\n",
    "    formatted_json = json.dumps(response_dict, indent=4)\n",
    "    print(formatted_json)\n",
    "    \n",
    "def serialize_and_print_completion(completion):\n",
    "    completion_json = serialize_completion(completion)\n",
    "    print_chat_completion(completion_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the completion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-A0S2AMEAXSpgqsUT2GjB16SMlvsGG\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"The capital of Poland is Warsaw.\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\",\n",
      "                \"function_call\": null,\n",
      "                \"tool_calls\": null\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1724671126,\n",
      "    \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"service_tier\": null,\n",
      "    \"system_fingerprint\": \"fp_f3db212e1c\",\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 7,\n",
      "        \"prompt_tokens\": 16,\n",
      "        \"total_tokens\": 23\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "serialize_and_print_completion(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
